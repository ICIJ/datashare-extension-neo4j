{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load data\n",
    "\n",
    "We restrict the data by entity type for now"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import dedupe\n",
    "\n",
    "dedupe_logger = logging.getLogger(dedupe.__name__)\n",
    "dedupe_logger.setLevel(logging.DEBUG)\n",
    "dedupe_logger.handlers = []\n",
    "dedupe_logger.addHandler(logging.StreamHandler())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "import neo4j\n",
    "\n",
    "neo4j_driver = neo4j.AsyncGraphDatabase.driver(\"neo4j://localhost:7687\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "DATASHARE_BASE_URL = \"http://localhost:8080\"\n",
    "DATASHARE_PROJECT_URL = f\"{DATASHARE_BASE_URL}/#/d/local-datashare\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "from typing import AsyncGenerator, Optional\n",
    "\n",
    "\n",
    "async def retrieve_ne(\n",
    "    session: neo4j.AsyncSession,\n",
    "    ne_category: str,\n",
    "    *,\n",
    "    limit: Optional[int] = None,\n",
    ") -> AsyncGenerator[neo4j.Record, None]:\n",
    "    query = f\"\"\"MATCH (ne:NamedEntity:{ne_category})-[rel]->(doc:Document)\n",
    "OPTIONAL MATCH (doc)-[HAS_PARENT]->(rootDoc:Document)\n",
    "RETURN ne, doc, rootDoc\n",
    "\"\"\"\n",
    "    if limit:\n",
    "        query = f\"\"\"{query}\n",
    "LIMIT {limit}\n",
    "\"\"\"\n",
    "    res = await session.run(query)\n",
    "    async for rec in res:\n",
    "        yield rec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from neo4j_app.ml.graph_dedupe import (\n",
    "    NE_DEBUG_DOC_URL,\n",
    "    NE_DEBUG_FILENAME,\n",
    "    NE_DOC_CONTENT_TYPE,\n",
    "    NE_DOC_DIR_NAME,\n",
    "    NE_DOC_FILENAME,\n",
    "    NE_DOC_ID,\n",
    "    NE_DOC_ROOT_ID,\n",
    ")\n",
    "from neo4j_app.constants import NE_MENTION_NORM\n",
    "import itertools\n",
    "import string"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from neo4j_app.constants import DOC_CONTENT_TYPE, DOC_DIRNAME, DOC_ID, DOC_PATH\n",
    "from typing import Dict\n",
    "\n",
    "_TRANSLATE_PUNCT = str.maketrans(dict(zip(string.punctuation, itertools.repeat(\" \"))))\n",
    "\n",
    "\n",
    "# TODO: refine this violent preprocessing...\n",
    "\n",
    "\n",
    "def _replace_double_white_spaces(s: str) -> str:\n",
    "    while \"  \" in s:\n",
    "        s = s.replace(\"  \", \" \")\n",
    "    return s\n",
    "\n",
    "\n",
    "def preprocess_filename(filename: str) -> Optional[str]:\n",
    "    filename = filename.translate(_TRANSLATE_PUNCT)\n",
    "    filename = _replace_double_white_spaces(filename)\n",
    "    if not filename:\n",
    "        filename = None\n",
    "    filename = filename.lower().strip()\n",
    "    return filename\n",
    "\n",
    "\n",
    "def preprocess_dirname(dirname: str) -> str:\n",
    "    dirname = \" \".join(item for item in dirname.split(\"/\") if item)\n",
    "    return dirname\n",
    "\n",
    "\n",
    "def doc_url(project_url: str, *, doc_id: str, root_id: Optional[str]) -> str:\n",
    "    return f\"{project_url}/{root_id if root_id is not None else doc_id}/{doc_id}\"\n",
    "\n",
    "\n",
    "def neo4j_to_record(record: neo4j.Record, project_url: str) -> Dict:\n",
    "    rec = dict()\n",
    "    ne = record[\"ne\"]\n",
    "    rec[NE_MENTION_NORM] = ne[NE_MENTION_NORM]\n",
    "    doc = record[\"doc\"]\n",
    "    rec[NE_DOC_ID] = doc[DOC_ID]\n",
    "    rec[NE_DOC_DIR_NAME] = preprocess_dirname(doc[DOC_DIRNAME])\n",
    "    raw_filename = doc[DOC_PATH].split(\"/\")[-1]\n",
    "    rec[NE_DOC_FILENAME] = preprocess_filename(raw_filename)\n",
    "    rec[NE_DOC_CONTENT_TYPE] = doc[DOC_CONTENT_TYPE]\n",
    "    root_doc = record[\"rootDoc\"]\n",
    "    root_id = None\n",
    "    if root_doc is not None:\n",
    "        root_id = root_doc[DOC_ID]\n",
    "    rec[NE_DOC_ROOT_ID] = root_id\n",
    "    # Debug\n",
    "    rec[NE_DEBUG_DOC_URL] = doc_url(\n",
    "        project_url, doc_id=rec[NE_DOC_ID], root_id=rec[NE_DOC_ROOT_ID]\n",
    "    )\n",
    "    rec[NE_DEBUG_FILENAME] = raw_filename\n",
    "    return rec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import csv\n",
    "from typing import AsyncIterable, List, TextIO\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from neo4j_app import ROOT_DIR\n",
    "\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"data\")\n",
    "records_path = DATA_PATH / \"person_records.csv\"\n",
    "training_set_path = DATA_PATH / \"person_training.csv\"\n",
    "trained_model_path = DATA_PATH / \"person_model.pickle\"\n",
    "clusters_path = DATA_PATH / \"person_clusters.csv\"\n",
    "excluded_set_path = DATA_PATH / \"excluded.txt\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from neo4j_app.ml.graph_dedupe import NE_FIELDNAMES, async_write_dataset\n",
    "\n",
    "# TODO: remove the limit of training data\n",
    "NUM_SAMPLES = None\n",
    "\n",
    "async with neo4j_driver.session() as sess:\n",
    "    if not records_path.exists():\n",
    "        with records_path.open(\"w\") as df:\n",
    "            recs = (\n",
    "                neo4j_to_record(rec, project_url=DATASHARE_PROJECT_URL)\n",
    "                async for rec in retrieve_ne(\n",
    "                    sess, ne_category=\"PERSON\", limit=NUM_SAMPLES\n",
    "                )\n",
    "            )\n",
    "            await async_write_dataset(recs, fieldnames=NE_FIELDNAMES, dataset_f=df)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import functools\n",
    "from neo4j_app.ml.graph_dedupe import DocumentGraphDedupe, person_fields, run_training\n",
    "\n",
    "# TODO: increase\n",
    "training_sample_size = 50000\n",
    "target_recall = 0.8\n",
    "\n",
    "\n",
    "model = run_training(\n",
    "    records_path,\n",
    "    dedupe_getter=functools.partial(DocumentGraphDedupe, doc_id=NE_DOC_ID),\n",
    "    fields_getter=functools.partial(person_fields, inside_doc=True),\n",
    "    excluded_path=excluded_set_path,\n",
    "    model_path=trained_model_path,\n",
    "    training_path=training_set_path,\n",
    "    sample_size=training_sample_size,\n",
    "    id_column=NE_MENTION_NORM,\n",
    "    recall=target_recall,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

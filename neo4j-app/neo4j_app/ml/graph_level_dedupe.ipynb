{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import dedupe\n",
    "\n",
    "dedupe_logger = logging.getLogger(dedupe.__name__)\n",
    "dedupe_logger.setLevel(logging.DEBUG)\n",
    "dedupe_logger.handlers = []\n",
    "dedupe_logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from neo4j_app import ROOT_DIR\n",
    "\n",
    "DATA_PATH = ROOT_DIR.joinpath(\"data\")\n",
    "records_path = DATA_PATH / \"person_records.csv\"\n",
    "trained_model_path = DATA_PATH / \"person_model.pickle\"\n",
    "excluded_set_path = DATA_PATH / \"excluded.txt\"\n",
    "clusters_path = DATA_PATH / \"person_clusters.json\"\n",
    "dedupe_path = DATA_PATH / \"person_deduped.csv\"\n",
    "training_set_path = DATA_PATH / \"person_training.csv\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "from dedupe import read_training\n",
    "\n",
    "with training_set_path.open() as f:\n",
    "    training_set = read_training(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load a sample of the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "from neo4j_app.constants import NE_MENTION_NORM\n",
    "from neo4j_app.ml.graph_dedupe import read_records\n",
    "\n",
    "with excluded_set_path.open() as f:\n",
    "    invalid_ids = (line.strip() for line in f)\n",
    "    invalid_ids = set(i for i in invalid_ids if i)\n",
    "\n",
    "with records_path.open() as f:\n",
    "    data = read_records(f, id_column=NE_MENTION_NORM, invalid_ids=invalid_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Downsample a bit the data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "from dedupe._typing import Data\n",
    "\n",
    "\n",
    "def sample_data(dataset: Data, n_samples: int, sort_keys: Sequence[str]) -> Data:\n",
    "    samples = sorted(dataset.items(), key=lambda i: tuple((i[1][k] for k in sort_keys)))\n",
    "    return dict(samples[:n_samples])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Compute graph level features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from dedupe._typing import RecordDict\n",
    "from typing import Dict, Generator, Iterable\n",
    "\n",
    "NE_MENTION_CLUSTER = \"neMentionClusterID\"\n",
    "\n",
    "\n",
    "def add_mention_cluster_field(\n",
    "    records: Iterable[RecordDict],\n",
    "    clusters: Dict,\n",
    "    *,\n",
    "    id_field: str,\n",
    "    cluster_field_name: str\n",
    ") -> Generator[RecordDict, None, None]:\n",
    "    for rec in records:\n",
    "        rec = deepcopy(rec)\n",
    "        rec[cluster_field_name] = clusters[rec[id_field]]\n",
    "        yield rec"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "with dedupe_path.open() as f:\n",
    "    doc_level_clusters = read_records(\n",
    "        f, id_column=NE_MENTION_NORM, invalid_ids=invalid_ids\n",
    "    )\n",
    "doc_level_clusters = {\n",
    "    rec_id: rec[NE_MENTION_NORM] for rec_id, rec in doc_level_clusters.items()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_SAMPLES = 20000\n",
    "data = sample_data(data, n_samples=N_SAMPLES, sort_keys=[\"docId\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "20000"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_keys, data_values = zip(*data.items())\n",
    "new_training_set = dict(zip(data_keys, add_mention_cluster_field(\n",
    "    data_values,\n",
    "    clusters=doc_level_clusters,\n",
    "    id_field=NE_MENTION_NORM,\n",
    "    cluster_field_name=NE_MENTION_CLUSTER,\n",
    ")))\n",
    "len(new_training_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make the most of the already annotated data\n",
    "\n",
    "Keep the training set, compute the new features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
